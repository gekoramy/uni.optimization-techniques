{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Optimization techniques Lab. 6: Bayesian Optimization\n",
    "## Introduction\n",
    "**Goal.** The goal of this lab is to study the behavior of Bayesian optimization on a regression problem and a classifier one. \n",
    "Bayesian optimization is a probabilistic approach that uses the Bayes' Theorem $P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}$. Briefly, we use the prior information, $P(A)$,(random samples) to optimize a surrogate function, $P(B|A)$.\n",
    "\n",
    "**Getting started.** The following cells contain the implementation of the methods that we will use throughout this lab, together with utilities. \n"
   ],
   "metadata": {
    "id": "eK4fQ2q-Xcx1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import catch_warnings, simplefilter\n",
    "from numpy import mean\n",
    "from scipy.optimize import OptimizeResult\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classifier\n",
    "---\n",
    "## Questions:\n",
    "- Try different ranges of hyperparameters. How do the results change?\n",
    "- Does the model influence the choice of the hyperparameters?"
   ],
   "metadata": {
    "id": "dzw4lTn9A5MK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=500, centers=3, n_features=2)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', s=20)\n",
    "plt.savefig('out/blobs.svg')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from skopt.space import Real\n",
    "\n",
    "# define the model\n",
    "# define the space of hyperparameters to search\n",
    "cases = [\n",
    "    ('random-forest-classifier', RandomForestClassifier, [\n",
    "        [\n",
    "            Integer(2, 3, name='n_estimators'),\n",
    "            Integer(1, 2, name='max_features')\n",
    "        ],\n",
    "        [\n",
    "            Integer(1, 5, name='n_estimators'),\n",
    "            Integer(1, 2, name='max_features')\n",
    "        ],\n",
    "        [\n",
    "            Integer(1, 4, name='n_estimators'),\n",
    "            Integer(1, 4, name='max_features')\n",
    "        ],\n",
    "\n",
    "    ]),\n",
    "    ('radius-neighbors-classifier', RadiusNeighborsClassifier, [\n",
    "        [\n",
    "            Integer(3, 7, name='radius'),\n",
    "            Integer(1, 3, name='p')\n",
    "        ],\n",
    "        [\n",
    "            Integer(5, 10, name='radius'),\n",
    "            Integer(1, 3, name='p')\n",
    "        ],\n",
    "    ]),\n",
    "    ('k-neighbors-classifier', KNeighborsClassifier, [\n",
    "        [\n",
    "            Integer(2, 3, name='n_neighbors'),\n",
    "            Integer(1, 2, name='p')\n",
    "        ],\n",
    "        [\n",
    "            Integer(1, 5, name='n_neighbors'),\n",
    "            Integer(1, 2, name='p')\n",
    "        ],\n",
    "        [\n",
    "            Integer(1, 4, name='n_neighbors'),\n",
    "            Integer(1, 4, name='p')\n",
    "        ],\n",
    "    ]),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for (n, m, search_spaces) in cases:\n",
    "    for search_space in search_spaces:\n",
    "        model = m()\n",
    "\n",
    "\n",
    "        # define the function used to evaluate a given configuration\n",
    "        @use_named_args(search_space)\n",
    "        def evaluate_model(**params) -> float:\n",
    "            # something\n",
    "            model.set_params(**params)\n",
    "            # calculate 5-fold cross validation\n",
    "            with catch_warnings():\n",
    "                # ignore generated warnings\n",
    "                simplefilter(\"ignore\")\n",
    "                scores = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "                # calculate the mean of the scores\n",
    "                estimate = mean(scores)\n",
    "                return 1.0 - estimate\n",
    "\n",
    "\n",
    "        # perform optimization\n",
    "        result: OptimizeResult = gp_minimize(evaluate_model, search_space)\n",
    "\n",
    "        os = Counter([str(i) for i in result.x_iters])\n",
    "        xs = [str([a, b]) for (a, b) in itertools.product(\n",
    "            range(search_space[0].low, 1 + search_space[0].high),\n",
    "            range(search_space[1].low, 1 + search_space[1].high)\n",
    "        )]\n",
    "        ys = [os.get(x, 0) for x in xs]\n",
    "\n",
    "        fig, (ax) = plt.subplots(1)\n",
    "        bs = ax.bar(xs, ys)\n",
    "        bs[xs.index(str([result.x[0], result.x[1]]))].set_color('green')\n",
    "        ax.set_title(f'accuracy = {(1.0 - result.fun) * 100}%\\n' + ', '.join([n.name for n in search_space]))\n",
    "        ax.tick_params('x', labelrotation=90)\n",
    "        fig.savefig(\n",
    "            f'out/{n} - [{(search_space[0].low, search_space[0].high)},{(search_space[1].low, search_space[1].high)}].svg')\n",
    "        plt.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BONUS\n",
    "\n",
    "You see in the classifier the effect of hyperparameter tuning. \n",
    "You can now change the acquisition functions in the regression problem, adding a slack variable as a hyperparameter. How does this variable affect the optimization problem?"
   ],
   "metadata": {
    "id": "EvVHVIoCqLWX"
   }
  }
 ]
}
