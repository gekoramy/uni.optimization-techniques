{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Optimization techniques Lab. 6: Bayesian Optimization\n",
    "## Introduction\n",
    "**Goal.** The goal of this lab is to study the behavior of Bayesian optimization on a regression problem and a classifier one. \n",
    "Bayesian optimization is a probabilistic approach that uses the Bayes' Theorem $P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}$. Briefly, we use the prior information, $P(A)$,(random samples) to optimize a surrogate function, $P(B|A)$.\n",
    "\n",
    "**Getting started.** The following cells contain the implementation of the methods that we will use throughout this lab, together with utilities. \n"
   ],
   "metadata": {
    "id": "eK4fQ2q-Xcx1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from typing import Tuple, Callable, List\n",
    "from warnings import catch_warnings, simplefilter\n",
    "from matplotlib import pyplot\n",
    "from numpy import arange, ndarray, sin, argmax, asarray, mean, vstack, pi\n",
    "from numpy.random import normal, random\n",
    "from scipy.stats import norm\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, Matern, RationalQuadratic, DotProduct\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classifier\n",
    "---\n",
    "## Questions:\n",
    "- Try different ranges of hyperparameters. How do the results change?\n",
    "- Does the model influence the choice of the hyperparameters?"
   ],
   "metadata": {
    "id": "dzw4lTn9A5MK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def classifier() -> None:\n",
    "    # generate 2d classification dataset\n",
    "    X, y = make_blobs(n_samples=500, centers=3, n_features=2)\n",
    "    # define the model\n",
    "\n",
    "    model = KNeighborsClassifier()\n",
    "    # define the space of hyperparameters to search\n",
    "    search_space = [Integer(1, 5, name='n_neighbors'), Integer(1, 2, name='p')]\n",
    "\n",
    "    # define the function used to evaluate a given configuration\n",
    "    @use_named_args(search_space)\n",
    "    def evaluate_model(**params):\n",
    "        # something\n",
    "        model.set_params(**params)\n",
    "        # calculate 5-fold cross validation\n",
    "        with catch_warnings():\n",
    "            # ignore generated warnings\n",
    "            simplefilter(\"ignore\")\n",
    "            result = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "            # calculate the mean of the scores\n",
    "            estimate = mean(result)\n",
    "            return 1.0 - estimate\n",
    "\n",
    "    # perform optimization\n",
    "    result = gp_minimize(evaluate_model, search_space)\n",
    "    # summarizing finding:\n",
    "    print('Best Accuracy: %.3f' % (1.0 - result.fun))\n",
    "    print('Best Parameters: n_neighbors=%d, p=%d' % (result.x[0], result.x[1]))\n",
    "\n",
    "\n",
    "classifier()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BONUS\n",
    "\n",
    "You see in the classifier the effect of hyperparameter tuning. \n",
    "You can now change the acquisition functions in the regression problem, adding a slack variable as a hyperparameter. How does this variable affect the optimization problem?"
   ],
   "metadata": {
    "id": "EvVHVIoCqLWX"
   }
  }
 ]
}
