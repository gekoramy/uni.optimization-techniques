{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 9: Design of Experiment\n",
    "In this lab, we will observe the effect of the DoE in the Bayesian optimization and Bio-inspired approaches.\n",
    "\n",
    "In the following (hidden) block, the utilities used for running the experiments are implemented.\n",
    "\n",
    "The list of available benchmark functions can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions)\n",
    "\n",
    "**NOTE**: When studying the effect of the parameters is *extremely* important to vary just one parameter at a time. Therefore, you are suggested to study one parameter by fixing all the others, and then moving to the next.\n",
    "\n",
    "Moreover, when comparing different algorithms, is *very* important to run each of them several times (e.g., 30) by using different initial random seeds.\n",
    "\n",
    "\n",
    "You will use the sampling technique seen in the lecture. In particular, you will have to implement:\n",
    "\n",
    "\n",
    "*   Random sampling\n",
    "*   The Halton sequence\n",
    "*   The full factorial sampling\n",
    "*   The Latin Hypercube sampling\n",
    "\n"
   ],
   "metadata": {
    "id": "1LFQ4RnHpEMu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code for the Bayesian Optimization, you have to reuse the code from Lab. 6 for the acquisition and the objective functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import more_itertools\n",
    "import pipe as p\n",
    "\n",
    "from typing import List, Tuple, Iterator, Callable\n",
    "from scipy.stats import norm\n",
    "\n",
    "from math import sin\n",
    "from math import pi\n",
    "from numpy import arange, ndarray\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skopt.space import Integer\n",
    "from skopt.utils import use_named_args\n",
    "from warnings import catch_warnings\n",
    "from skopt import gp_minimize\n",
    "from warnings import simplefilter\n",
    "\n",
    "import cma\n",
    "import inspyred\n",
    "import importlib\n",
    "import functools\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from inspyred import ec\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "import benchmark_functions as bf\n",
    "from matplotlib import pyplot as plt\n",
    "from inspyred.ec import EvolutionaryComputation\n",
    "from inspyred.ec import selectors, replacers, terminators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(x: float, noise: float = 0.05) -> float:\n",
    "    return sin(3 * 2 * pi * x) + np.random.uniform(-noise, noise)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "XS = arange(0, 1, 0.001).reshape(-1, 1)\n",
    "YS = objective(XS, 0)\n",
    "\n",
    "\n",
    "def surrogate(model: GaussianProcessRegressor, X: ndarray[float]) -> Tuple[ndarray[float], ndarray[float]]:\n",
    "    \"\"\"\n",
    "    surrogate or approximation for the objective function\n",
    "    \"\"\"\n",
    "\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")\n",
    "        return model.predict(X, return_std=True)\n",
    "\n",
    "\n",
    "def opt_acquisition(\n",
    "        xs_known: ndarray[float],\n",
    "        ys_known: ndarray[float],\n",
    "        model: GaussianProcessRegressor,\n",
    "        acquisition: Callable[[ndarray[float], ndarray[float], GaussianProcessRegressor], ndarray[float]]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    optimize the acquisition function\n",
    "    \"\"\"\n",
    "\n",
    "    # random search, generate random samples\n",
    "    xs_unknown: ndarray[float] = random(50)\n",
    "    xs_unknown = xs_unknown.reshape(-1, 1)\n",
    "\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(xs_known, xs_unknown, model)\n",
    "\n",
    "    # locate the index of the largest scores\n",
    "    ix = argmax(scores)\n",
    "    return xs_unknown[ix, 0]\n",
    "\n",
    "\n",
    "def bayesian_optimization(\n",
    "        generation: int,\n",
    "        model: GaussianProcessRegressor,\n",
    "        acquisition: Callable[[ndarray[float], ndarray[float], GaussianProcessRegressor], ndarray[float]],\n",
    "        initial_points: List[float],\n",
    "        file: str\n",
    ") -> Tuple[ndarray[float], ndarray[float], GaussianProcessRegressor]:\n",
    "    # reshape into rows and cols\n",
    "    xs_known = asarray(initial_points).reshape(-1, 1)\n",
    "    ys_known = asarray([objective(x) for x in xs_known]).reshape(-1, 1)\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(xs_known, ys_known)\n",
    "\n",
    "    # perform the optimization process\n",
    "    for i in range(generation):\n",
    "        # select the next point\n",
    "        # and sample it\n",
    "        x_next = opt_acquisition(xs_known, ys_known, model, acquisition)\n",
    "        y_next = objective(x_next)\n",
    "\n",
    "        # region plot\n",
    "        fig, (ax1, ax2) = pyplot.subplots(2, sharex=True, height_ratios=[3, 1], gridspec_kw={'hspace': 0})\n",
    "        plot_approximation(ax1, model, xs_known, ys_known, x_next)\n",
    "        plot_acquisition(ax2, model, xs_known, acquisition, x_next)\n",
    "        if i == 0:\n",
    "            lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "            lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "            fig.legend(lines, labels, loc='upper left')\n",
    "        pyplot.savefig(f'{file} {i}.svg')\n",
    "        # endregion\n",
    "\n",
    "        # add the data to the dataset\n",
    "        xs_known = vstack((xs_known, [[x_next]]))\n",
    "        ys_known = vstack((ys_known, [[y_next]]))\n",
    "\n",
    "        # update the model\n",
    "        model.fit(xs_known, ys_known)\n",
    "\n",
    "    pyplot.close()\n",
    "    return xs_known, ys_known, model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def plot_approximation(\n",
    "        ax,\n",
    "        model,\n",
    "        xs_known,\n",
    "        ys_known,\n",
    "        x_next,\n",
    "):\n",
    "    mu, std = model.predict(XS, return_std=True)\n",
    "    ax.fill_between(\n",
    "        XS.ravel(),\n",
    "        mu.ravel() + 1.96 * std,\n",
    "        mu.ravel() - 1.96 * std,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        XS.ravel(),\n",
    "        YS.ravel() + 0.05,\n",
    "        YS.ravel() - 0.05,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    ax.plot(XS, YS, 'y--', lw=1, label='objective')\n",
    "    ax.plot(XS, mu, 'b-', lw=1, label='surrogate function')\n",
    "    ax.plot(xs_known, ys_known, 'kx', mew=3, label='noisy samples')\n",
    "    ax.axvline(x=x_next, ls='--', c='k', lw=1)\n",
    "\n",
    "\n",
    "def plot_acquisition(\n",
    "        ax,\n",
    "        model,\n",
    "        xs_known,\n",
    "        acquisition: Callable[[ndarray[float], ndarray[float], GaussianProcessRegressor], ndarray[float]],\n",
    "        x_next,\n",
    "):\n",
    "    ax.plot(XS, acquisition(xs_known, XS, model), 'r-', lw=1, label='Acquisition function')\n",
    "    ax.axvline(x=x_next, ls='--', c='k', lw=1, label='Next sampling location')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def probability_of_improvement(\n",
    "        xs_known: ndarray[float],\n",
    "        xs_unknown: ndarray[float],\n",
    "        model: GaussianProcessRegressor\n",
    ") -> ndarray[float]:\n",
    "    y_hat, _ = surrogate(model, xs_known)\n",
    "    best = max(y_hat)\n",
    "\n",
    "    mu, sd = surrogate(model, xs_unknown)\n",
    "    z = (best - mu) / sd\n",
    "\n",
    "    return norm.cdf(-z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def expected_improvement(\n",
    "        xs_known: ndarray[float],\n",
    "        xs_unknown: ndarray[float],\n",
    "        model: GaussianProcessRegressor,\n",
    ") -> ndarray[float]:\n",
    "    y_hat, _ = surrogate(model, xs_known)\n",
    "    best = max(y_hat)\n",
    "\n",
    "    mu, sd = surrogate(model, xs_unknown)\n",
    "    z = (best - mu) / sd\n",
    "\n",
    "    return (mu - best) * norm.cdf(-z) + sd * norm.pdf(-z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code for the Genetic algorithm from lab. 7"
   ],
   "metadata": {
    "id": "7Hg7Wyob6nr1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0qLDcl3jj0f",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "GLOBAL = 'Global'\n",
    "INDIVIDUAL = 'Individual'\n",
    "CORRELATED = 'Correlated'\n",
    "STAR = 'star'\n",
    "RING = 'ring'\n",
    "\n",
    "\n",
    "class OptFun():\n",
    "    def __init__(self, wf):\n",
    "        self.f = wf\n",
    "        self.history = []\n",
    "        self.__name__ = f'OptFun({wf.__class__})'\n",
    "\n",
    "    def __call__(self, candidates, *args, **kwargs):\n",
    "        y = []\n",
    "        for x0 in candidates:\n",
    "            self.history.append(deepcopy(x0))\n",
    "            y.append(self.f(x0))\n",
    "        return y\n",
    "\n",
    "    def minima(self):\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounder(self):\n",
    "        def fcn(candidate, *args):\n",
    "            bounds = self.f.suggested_bounds()\n",
    "\n",
    "            for i, (m, M) in enumerate(zip(*bounds)):\n",
    "                if candidate[i] < m:\n",
    "                    candidate[i] = m\n",
    "                if candidate[i] > M:\n",
    "                    candidate[i] = M\n",
    "            return candidate\n",
    "\n",
    "        return fcn\n",
    "\n",
    "    def bounds(self):\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def heatmap(self, file=None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.asarray([[self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x, y, Z, 15, linewidths=0.5, colors='k')  # height lines\n",
    "        plt.contourf(x, y, Z, 15, cmap='viridis', vmin=Z.min(), vmax=Z.max())  # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history) > 0:  # plot points\n",
    "            xdata = [x for [x, _] in self.history]\n",
    "            ydata = [y for [_, y] in self.history]\n",
    "            plt.plot(xdata, ydata, 'or', markersize=3)\n",
    "        if file is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            fig.savefig(file, dpi=400)\n",
    "        plt.close()\n",
    "\n",
    "    def heatmapP(self, window: int, init: int = 0, file=None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "\n",
    "        y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.asarray([[self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x, y, Z, 15, linewidths=0.5, colors='k')  # height lines\n",
    "        plt.contourf(x, y, Z, 15, cmap='viridis', vmin=Z.min(), vmax=Z.max())  # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history) > 0:  # plot points\n",
    "\n",
    "            plt.plot(\n",
    "                [x for [x, _] in self.history[:init]],\n",
    "                [y for [_, y] in self.history[:init]],\n",
    "                'ow',\n",
    "                markersize=3,\n",
    "                alpha=0.5\n",
    "            )\n",
    "\n",
    "            list(self.history[init:]\n",
    "                 | p.Pipe(lambda ps: more_itertools.windowed(ps, n=window, step=window))\n",
    "                 | p.izip(it.count(1))\n",
    "                 | p.map(lambda ps: plt.plot([x for [x, _] in ps[0]], [y for [_, y] in ps[0]], 'or', markersize=3,\n",
    "                                             alpha=0.1 + 0.9 * (ps[1] / (len(self.history) / window))))\n",
    "                 )\n",
    "\n",
    "        if file is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            fig.savefig(file, dpi=400)\n",
    "        plt.close()\n",
    "\n",
    "    def plot(self):\n",
    "        plt.clf()\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        min = func.minima()[0].score\n",
    "        plt.plot(values)\n",
    "        plt.axhline(min, color=\"r\", label=\"optimum\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_bounds(self, bounds):\n",
    "        new_bounds = []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self):\n",
    "        return len(self.history)\n",
    "\n",
    "\n",
    "def choice_without_replacement(rng, n, size):\n",
    "    result = set()\n",
    "    while len(result) < size:\n",
    "        result.add(rng.randint(0, n))\n",
    "    return result\n",
    "\n",
    "\n",
    "class NumpyRandomWrapper(RandomState):\n",
    "    def __init__(self, seed=None):\n",
    "        super(NumpyRandomWrapper, self).__init__(seed)\n",
    "\n",
    "    def sample(self, population, k):\n",
    "        if isinstance(population, int):\n",
    "            population = range(population)\n",
    "\n",
    "        return asarray([population[i] for i in\n",
    "                        choice_without_replacement(self, len(population), k)])\n",
    "        #return #self.choice(population, k, replace=False)\n",
    "\n",
    "    def random(self):\n",
    "        return self.random_sample()\n",
    "\n",
    "    def gauss(self, mu, sigma):\n",
    "        return self.normal(mu, sigma)\n",
    "\n",
    "\n",
    "def initial_pop_observer(population, num_generations, num_evaluations,\n",
    "                         args):\n",
    "    if num_generations == 0:\n",
    "        args[\"initial_pop_storage\"][\"individuals\"] = asarray([guy.candidate\n",
    "                                                              for guy in population])\n",
    "        args[\"initial_pop_storage\"][\"fitnesses\"] = asarray([guy.fitness\n",
    "                                                            for guy in population])\n",
    "\n",
    "\n",
    "def generator(case):\n",
    "    if case == \"random\":\n",
    "        return random_generator\n",
    "    if case == \"LHS\":\n",
    "        return lhs_generator\n",
    "    if case == \"Halton\":\n",
    "        return Halton_generator\n",
    "    if case == \"FF\":\n",
    "        return ff_generator\n",
    "\n",
    "\n",
    "def generator_wrapper(func):\n",
    "    @functools.wraps(func)\n",
    "    def _generator(random, args):\n",
    "        return asarray(func(random, args))\n",
    "\n",
    "    return _generator\n",
    "\n",
    "\n",
    "def single_objective_evaluator(candidates, args):\n",
    "    problem = args[\"problem\"]\n",
    "    return [CombinedObjectives(fit, args) for fit in\n",
    "            problem.evaluator(candidates, args)]\n",
    "\n",
    "\n",
    "def run_ga(random, generator_type, func, num_vars=0,\n",
    "           maximize=False, **kwargs):\n",
    "    #create dictionaries to store data about initial population, and lines\n",
    "    initial_pop_storage = {}\n",
    "\n",
    "    algorithm = ec.EvolutionaryComputation(random)\n",
    "    algorithm.terminator = ec.terminators.generation_termination\n",
    "    algorithm.replacer = ec.replacers.generational_replacement\n",
    "    algorithm.variator = [ec.variators.uniform_crossover, ec.variators.gaussian_mutation]\n",
    "    algorithm.selector = ec.selectors.tournament_selection\n",
    "\n",
    "    algorithm.observer = initial_pop_observer\n",
    "\n",
    "    kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "\n",
    "    kwargs[\"bounder\"] = func.bounder()\n",
    "    kwargs[\"generator\"] = generator(generator_type)\n",
    "\n",
    "    final_pop = algorithm.evolve(evaluator=func,\n",
    "                                 maximize=False,\n",
    "                                 initial_pop_storage=initial_pop_storage,\n",
    "                                 num_vars=num_vars,\n",
    "                                 **kwargs)\n",
    "\n",
    "    #best_guy = final_pop[0].candidate\n",
    "    #best_fitness = final_pop[0].fitness\n",
    "    final_pop_fitnesses = asarray([guy.fitness for guy in final_pop])\n",
    "    final_pop_candidates = asarray([guy.candidate for guy in final_pop])\n",
    "\n",
    "    sort_indexes = sorted(range(len(final_pop_fitnesses)), key=final_pop_fitnesses.__getitem__)\n",
    "    final_pop_fitnesses = final_pop_fitnesses[sort_indexes]\n",
    "    final_pop_candidates = final_pop_candidates[sort_indexes]\n",
    "\n",
    "    best_guy = final_pop_candidates[0]\n",
    "    best_fitness = final_pop_fitnesses[0]\n",
    "\n",
    "    return best_guy, best_fitness, final_pop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Samplings methods to implement"
   ],
   "metadata": {
    "id": "3YjLWcgj7OVy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def random_generator(\n",
    "        n: int,\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        rnd: Generator,\n",
    ") -> ndarray[float]:\n",
    "    if len(boundaries) == 1:\n",
    "        [(start, stop)] = boundaries\n",
    "        return rnd.uniform(low=start, high=stop, size=n)\n",
    "\n",
    "    return np.asarray([rnd.uniform(low=start, high=stop, size=n) for (start, stop) in boundaries]).T\n",
    "\n",
    "\n",
    "def lhs_generator(\n",
    "        n: int,\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        rnd: Generator,\n",
    ") -> ndarray[float]:\n",
    "    if len(boundaries) == 1:\n",
    "        [(start, stop)] = boundaries\n",
    "        return start + (4 + norm.ppf(\n",
    "            [\n",
    "                (i + 1 - rnd.uniform()) / n\n",
    "                for i\n",
    "                in rnd.permutation(n)\n",
    "            ]\n",
    "        )) * (stop - start) / 8\n",
    "\n",
    "    return np.asarray(\n",
    "        [\n",
    "            start + (4 + norm.ppf(\n",
    "                [\n",
    "                    (i + 1 - rnd.uniform()) / n\n",
    "                    for i\n",
    "                    in rnd.permutation(n)\n",
    "                ]\n",
    "            )) * (stop - start) / 8\n",
    "            for (start, stop)\n",
    "            in boundaries\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def Halton_generator(\n",
    "        n: int,\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        bases: List[int]\n",
    ") -> ndarray[float]:\n",
    "    def gen(start: int, stop: int, base: int) -> Iterator[float]:\n",
    "        n, d = 0, 1\n",
    "        for _ in range(n):\n",
    "            x = d - n\n",
    "            if x == 1:\n",
    "                n = 1\n",
    "                d *= base\n",
    "            else:\n",
    "                y = d // base\n",
    "                while x <= y:\n",
    "                    y //= base\n",
    "                n = (base + 1) * y - x\n",
    "            yield start + ((n / d) * (stop - start))\n",
    "\n",
    "    if len(boundaries) == 1:\n",
    "        [(start, stop)] = boundaries\n",
    "        [base] = bases\n",
    "        return np.fromiter(iter=gen(start, stop, base), dtype=float)\n",
    "\n",
    "    return np.asarray(\n",
    "        [np.fromiter(iter=gen(start, stop, base), dtype=float) for [(start, stop), base] in zip(boundaries, bases)]\n",
    "    )\n",
    "\n",
    "\n",
    "def ff_generator(\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        m: int\n",
    ") -> ndarray[float]:\n",
    "    if len(boundaries) == 1:\n",
    "        [(start, stop)] = boundaries\n",
    "        return np.linspace(start=start, stop=stop, num=m)\n",
    "\n",
    "    return np.asarray(\n",
    "        it.product(*[np.linspace(start=start, stop=stop, num=m) for (start, stop) in boundaries])\n",
    "    )\n"
   ],
   "metadata": {
    "id": "ic7JlvOI60fo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1: Bayesian Optmization"
   ],
   "metadata": {
    "id": "uNxjVNUu9qBM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def bo() -> None:\n",
    "    xs: ndarray[float]\n",
    "    ys: ndarray[float]\n",
    "    model: GaussianProcessRegressor\n",
    "    xs, ys, model = bayesian_optimization(\n",
    "        generation=10,\n",
    "        model=GaussianProcessRegressor(),\n",
    "        acquisition=expected_improvement,\n",
    "        initial_points=[1 / 3],\n",
    "        file='ei/ei exp-sine-squared one-third'\n",
    "    )\n",
    "\n",
    "    ix: ndarray[int] = argmax(ys)\n",
    "    print('Best Result: x=%.3f, y=%.3f' % (xs[ix], ys[ix]))\n",
    "\n",
    "\n",
    "bo()"
   ],
   "metadata": {
    "id": "XNDa4uDM9ntm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2: Genetic Algorithm"
   ],
   "metadata": {
    "id": "TE2uwsRa5sTS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bfs = [\n",
    "    (\"ackley\", bf.Ackley(), None),\n",
    "    (\"de jong 3\", bf.DeJong3(), None),\n",
    "    (\"keane\", bf.Keane(), -0.68),\n",
    "    (\"picheny goldstein and price\", bf.PichenyGoldsteinAndPrice(), None),\n",
    "    (\"mc cormick\", bf.McCormick(), None),\n",
    "    (\"michalewicz\", bf.Michalewicz(), None),\n",
    "    (\"styblinski and tang\", bf.StyblinskiTang(), None),\n",
    "    (\"easom\", bf.Easom(), None),\n",
    "    (\"pits and holes\", bf.PitsAndHoles(), None),\n",
    "    (\"egg holder\", bf.EggHolder(), None),\n",
    "]\n",
    "\n",
    "\n",
    "def f(fni, history):\n",
    "    x = OptFun(fni)\n",
    "    x.history = history\n",
    "    return x\n",
    "\n",
    "\n",
    "shutil.rmtree(\"out\")\n",
    "Path(\"out\").mkdir(parents=True, exist_ok=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ga() -> None:\n",
    "    for (name, fn, minima) in bfs:\n",
    "        func = OptFun(fn)\n",
    "\n",
    "        args = dict(\n",
    "            num_vars=2,  # number of dimensions of the search space\n",
    "            gaussian_stdev=1.0,  # standard deviation of the Gaussian mutations\n",
    "            tournament_size=2,\n",
    "            num_elites=1,  # number of elite individuals to maintain in each gen\n",
    "            pop_size=20,  # population size\n",
    "            pop_init_range=func.bounds()[0],  # range for the initial population\n",
    "            max_generations=3 ** 4 - 1,  # number of generations of the GA\n",
    "            crossover_rate=0.9,\n",
    "            mutation_rate=0.1\n",
    "        )\n",
    "\n",
    "        run_ga(\n",
    "            np.random.default_rng(seed=0),  # seeded random number generator\n",
    "            func,\n",
    "            **args\n",
    "        )\n",
    "\n",
    "        # list(\n",
    "        #     func.history\n",
    "        #     | p.Pipe(lambda xs: more_itertools.windowed(xs, n=args['pop_size'],   step=args['pop_size']))\n",
    "        #     | p.map(lambda x: f(fn, x))\n",
    "        #     | p.izip(it.count(0))\n",
    "        #     | p.map(lambda x: x[0].heatmap(file=f'out/heatmap {name} {x[1]}.svg'))\n",
    "        # )\n",
    "\n",
    "        list(\n",
    "            range(1, 5)\n",
    "            | p.map(lambda x: args['pop_size'] * (3 ** x))\n",
    "            | p.map(lambda x: f(fn, func.history[:x]))\n",
    "            | p.izip(it.count(0))\n",
    "            | p.map(lambda x: x[0].heatmapP(window=args['pop_size'], file=f'out/heatmap {name}   {x[1]}.svg'))\n",
    "        )\n",
    "\n",
    "        func.plot(minima=minima, file=f'out/trend {name}.svg')\n",
    "\n",
    "\n",
    "ga()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this lab, you will need to compare the algorithms studied in the previous lessons with their version enhanced with different DOE techniques.\n",
    "\n",
    "1.   How do the performances increases? Are the algorithms faster to converge, or can they find better solutions? \n",
    "2.   Is there an approach better than the others in terms of performance?\n",
    "3.   How much do the DOEs affect the search cost? \n"
   ],
   "metadata": {
    "id": "gSFPcYQirNga"
   }
  }
 ]
}
