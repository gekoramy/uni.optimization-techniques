{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 9: Design of Experiment\n",
    "In this lab, we will observe the effect of the DoE in the Bayesian optimization and Bio-inspired approaches.\n",
    "\n",
    "In the following (hidden) block, the utilities used for running the experiments are implemented.\n",
    "\n",
    "The list of available benchmark functions can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions)\n",
    "\n",
    "**NOTE**: When studying the effect of the parameters is *extremely* important to vary just one parameter at a time. Therefore, you are suggested to study one parameter by fixing all the others, and then moving to the next.\n",
    "\n",
    "Moreover, when comparing different algorithms, is *very* important to run each of them several times (e.g., 30) by using different initial random seeds.\n",
    "\n",
    "\n",
    "You will use the sampling technique seen in the lecture. In particular, you will have to implement:\n",
    "\n",
    "\n",
    "*   Random sampling\n",
    "*   The Halton sequence\n",
    "*   The full factorial sampling\n",
    "*   The Latin Hypercube sampling\n",
    "\n"
   ],
   "metadata": {
    "id": "1LFQ4RnHpEMu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code for the Bayesian Optimization, you have to reuse the code from Lab. 6 for the acquisition and the objective functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import shutil\n",
    "from builtins import float\n",
    "from typing import Iterator, Union, Tuple, Callable, List\n",
    "from warnings import catch_warnings, simplefilter\n",
    "\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "import pipe as p\n",
    "import scipy as sp\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(x: float, noise: float = 0.1) -> float:\n",
    "    return x ** 2 * np.sin(8 * np.pi * x) + np.random.uniform(-noise, noise)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# region bo\n",
    "XS = np.arange(0, 1, 0.001).reshape(-1, 1)\n",
    "YS = objective(XS, 0)\n",
    "\n",
    "\n",
    "def surrogate(model: GaussianProcessRegressor, X: np.ndarray[float]) -> Tuple[np.ndarray[float], np.ndarray[float]]:\n",
    "    \"\"\"\n",
    "    surrogate or approximation for the objective function\n",
    "    \"\"\"\n",
    "\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")\n",
    "        return model.predict(X, return_std=True)\n",
    "\n",
    "\n",
    "def opt_acquisition(\n",
    "        rnd: np.random.Generator,\n",
    "        xs_known: np.ndarray[float],\n",
    "        ys_known: np.ndarray[float],\n",
    "        model: GaussianProcessRegressor,\n",
    "        acquisition: Callable[[np.ndarray[float], np.ndarray[float], GaussianProcessRegressor], np.ndarray[float]]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    optimize the acquisition function\n",
    "    \"\"\"\n",
    "\n",
    "    # random search, generate random samples\n",
    "    xs_unknown: np.ndarray[float] = rnd.random(50)\n",
    "    xs_unknown = xs_unknown.reshape(-1, 1)\n",
    "\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(xs_known, xs_unknown, model)\n",
    "\n",
    "    # locate the index of the largest scores\n",
    "    ix = np.argmax(scores)\n",
    "    return xs_unknown[ix, 0]\n",
    "\n",
    "\n",
    "def bayesian_optimization(\n",
    "        rnd: np.random.Generator,\n",
    "        generation: int,\n",
    "        model: GaussianProcessRegressor,\n",
    "        acquisition: Callable[[np.ndarray[float], np.ndarray[float], GaussianProcessRegressor], np.ndarray[float]],\n",
    "        initial_points: np.ndarray[np.ndarray[float]],\n",
    "        file: str\n",
    ") -> Tuple[np.ndarray[float], np.ndarray[float], GaussianProcessRegressor]:\n",
    "    # reshape into rows and cols\n",
    "    xs_known = initial_points.reshape(-1, 1)\n",
    "    ys_known = np.asarray([objective(x) for x in xs_known]).reshape(-1, 1)\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(xs_known, ys_known)\n",
    "\n",
    "    # perform the optimization process\n",
    "    for i in range(generation):\n",
    "        # select the next point\n",
    "        # and sample it\n",
    "        x_next = opt_acquisition(rnd, xs_known, ys_known, model, acquisition)\n",
    "        y_next = objective(x_next)\n",
    "\n",
    "        # region plot\n",
    "        fig, (ax1, ax2) = plt.subplots(2, sharex=True, height_ratios=[3, 1], gridspec_kw={'hspace': 0})\n",
    "        plot_approximation(ax1, model, xs_known, ys_known, x_next)\n",
    "        plot_acquisition(ax2, model, xs_known, acquisition, x_next)\n",
    "        if i == 0:\n",
    "            fig.legend(loc='upper left')\n",
    "        fig.savefig(f'{file} {i}.svg')\n",
    "        plt.close('all')\n",
    "        # endregion\n",
    "\n",
    "        # add the data to the dataset\n",
    "        xs_known = np.vstack((xs_known, [[x_next]]))\n",
    "        ys_known = np.vstack((ys_known, [[y_next]]))\n",
    "\n",
    "        # update the model\n",
    "        model.fit(xs_known, ys_known)\n",
    "\n",
    "    return xs_known, ys_known, model\n",
    "\n",
    "# endregion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# region bo plots\n",
    "def plot_approximation(\n",
    "        ax,\n",
    "        model,\n",
    "        xs_known,\n",
    "        ys_known,\n",
    "        x_next,\n",
    "):\n",
    "    mu, std = model.predict(XS, return_std=True)\n",
    "    ax.fill_between(\n",
    "        XS.ravel(),\n",
    "        mu.ravel() + 1.96 * std,\n",
    "        mu.ravel() - 1.96 * std,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        XS.ravel(),\n",
    "        YS.ravel() + 0.1,\n",
    "        YS.ravel() - 0.1,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    ax.plot(XS, YS, 'y--', lw=1, label='objective')\n",
    "    ax.plot(XS, mu, 'b-', lw=1, label='surrogate function')\n",
    "    ax.plot(xs_known, ys_known, 'kx', mew=3, label='noisy samples')\n",
    "    ax.axvline(x=x_next, ls='--', c='k', lw=1)\n",
    "\n",
    "\n",
    "def plot_acquisition(\n",
    "        ax,\n",
    "        model,\n",
    "        xs_known,\n",
    "        acquisition: Callable[[np.ndarray[float], np.ndarray[float], GaussianProcessRegressor], np.ndarray[float]],\n",
    "        x_next,\n",
    "):\n",
    "    ax.plot(XS, acquisition(xs_known, XS, model), 'r-', lw=1, label='Acquisition function')\n",
    "    ax.axvline(x=x_next, ls='--', c='k', lw=1, label='Next sampling location')\n",
    "\n",
    "# endregion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# region bo implementations\n",
    "def probability_of_improvement(\n",
    "        xs_known: np.ndarray[float],\n",
    "        xs_unknown: np.ndarray[float],\n",
    "        model: GaussianProcessRegressor\n",
    ") -> np.ndarray[float]:\n",
    "    y_hat, _ = surrogate(model, xs_known)\n",
    "    best = max(y_hat)\n",
    "\n",
    "    mu, sd = surrogate(model, xs_unknown)\n",
    "    z = (best - mu) / sd\n",
    "\n",
    "    return sp.stats.norm.cdf(-z)\n",
    "\n",
    "\n",
    "def expected_improvement(\n",
    "        xs_known: np.ndarray[float],\n",
    "        xs_unknown: np.ndarray[float],\n",
    "        model: GaussianProcessRegressor,\n",
    ") -> np.ndarray[float]:\n",
    "    y_hat, _ = surrogate(model, xs_known)\n",
    "    best = max(y_hat)\n",
    "\n",
    "    mu, sd = surrogate(model, xs_unknown)\n",
    "    z = (best - mu) / sd\n",
    "\n",
    "    return (mu - best) * sp.stats.norm.cdf(-z) + sd * sp.stats.norm.pdf(-z)\n",
    "\n",
    "# endregion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code for the Genetic algorithm from lab. 7"
   ],
   "metadata": {
    "id": "7Hg7Wyob6nr1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pylab import *\n",
    "from inspyred import ec\n",
    "from copy import deepcopy\n",
    "\n",
    "import benchmark_functions as bf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0qLDcl3jj0f",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# region ga\n",
    "GLOBAL = 'Global'\n",
    "INDIVIDUAL = 'Individual'\n",
    "CORRELATED = 'Correlated'\n",
    "STAR = 'star'\n",
    "RING = 'ring'\n",
    "\n",
    "\n",
    "class OptFun():\n",
    "    def __init__(self, wf):\n",
    "        self.f = wf\n",
    "        self.history = []\n",
    "        self.__name__ = f'OptFun({wf.__class__})'\n",
    "\n",
    "    def __call__(self, candidates, *args, **kwargs):\n",
    "        y = []\n",
    "        for x0 in candidates:\n",
    "            self.history.append(deepcopy(x0))\n",
    "            y.append(self.f(x0))\n",
    "        return y\n",
    "\n",
    "    def minima(self):\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounder(self):\n",
    "        def fcn(candidate, *args):\n",
    "            bounds = self.f.suggested_bounds()\n",
    "\n",
    "            for i, (m, M) in enumerate(zip(*bounds)):\n",
    "                if candidate[i] < m:\n",
    "                    candidate[i] = m\n",
    "                if candidate[i] > M:\n",
    "                    candidate[i] = M\n",
    "            return candidate\n",
    "\n",
    "        return fcn\n",
    "\n",
    "    def bounds(self):\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def heatmap(self, file=None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.asarray([[self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x, y, Z, 15, linewidths=0.5, colors='k')  # height lines\n",
    "        plt.contourf(x, y, Z, 15, cmap='viridis', vmin=Z.min(), vmax=Z.max())  # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history) > 0:  # plot points\n",
    "            xdata = [x for [x, _] in self.history]\n",
    "            ydata = [y for [_, y] in self.history]\n",
    "            plt.plot(xdata, ydata, 'or', markersize=3)\n",
    "        if file is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            fig.savefig(file, dpi=400)\n",
    "        plt.close('all')\n",
    "\n",
    "    def heatmapP(self, window: int, init: int = 0, file=None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "\n",
    "        y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.asarray([[self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x, y, Z, 15, linewidths=0.5, colors='k')  # height lines\n",
    "        plt.contourf(x, y, Z, 15, cmap='viridis', vmin=Z.min(), vmax=Z.max())  # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history) > 0:  # plot points\n",
    "\n",
    "            plt.plot(\n",
    "                [x for [x, _] in self.history[:init]],\n",
    "                [y for [_, y] in self.history[:init]],\n",
    "                'ow',\n",
    "                markersize=3,\n",
    "                alpha=0.5\n",
    "            )\n",
    "\n",
    "            list(self.history[init:]\n",
    "                 | p.Pipe(lambda ps: more_itertools.windowed(ps, n=window, step=window))\n",
    "                 | p.izip(it.count(1))\n",
    "                 | p.map(lambda ps: plt.plot([x for [x, _] in ps[0]], [y for [_, y] in ps[0]], 'or', markersize=3,\n",
    "                                             alpha=0.1 + 0.9 * (ps[1] / (len(self.history) / window))))\n",
    "                 )\n",
    "\n",
    "        if file is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            fig.savefig(file, dpi=400)\n",
    "        plt.close('all')\n",
    "\n",
    "    def plot(self, minima=None, file=None):\n",
    "        plt.clf()\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        m = min(\n",
    "            [np.Inf if minima is None else minima] +\n",
    "            [self.f.minimum().score] +\n",
    "            list(self.f.minima() | p.map(lambda x: x.score))\n",
    "        )\n",
    "        plt.plot(values)\n",
    "        plt.axhline(m, color=\"r\", label=\"optimum\")\n",
    "        plt.legend()\n",
    "        if file is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(file, dpi=400)\n",
    "        plt.close('all')\n",
    "\n",
    "    def _convert_bounds(self, bounds):\n",
    "        new_bounds = []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self):\n",
    "        return len(self.history)\n",
    "\n",
    "\n",
    "def choice_without_replacement(rng: np.random.RandomState, n, size):\n",
    "    return rng.choice(range(0, n), size=size, replace=False)\n",
    "\n",
    "\n",
    "class NumpyRandomWrapper(np.random.RandomState):\n",
    "    def __init__(self, seed=None):\n",
    "        super(NumpyRandomWrapper, self).__init__(seed)\n",
    "\n",
    "    def sample(self, population, k):\n",
    "        if isinstance(population, int):\n",
    "            population = range(population)\n",
    "\n",
    "        return np.asarray([\n",
    "            population[i]\n",
    "            for i\n",
    "            in choice_without_replacement(self, len(population), k)\n",
    "        ])\n",
    "        #return #self.choice(population, k, replace=False)\n",
    "\n",
    "    def random(self):\n",
    "        return self.random_sample()\n",
    "\n",
    "    def gauss(self, mu, sigma):\n",
    "        return self.normal(mu, sigma)\n",
    "\n",
    "\n",
    "def initial_pop_observer(\n",
    "        population,\n",
    "        num_generations,\n",
    "        num_evaluations,\n",
    "        args\n",
    "):\n",
    "    if num_generations == 0:\n",
    "        args[\"initial_pop_storage\"][\"individuals\"] = np.asarray([guy.candidate for guy in population])\n",
    "        args[\"initial_pop_storage\"][\"fitnesses\"] = np.asarray([guy.fitness for guy in population])\n",
    "\n",
    "\n",
    "def generator_wrapper(func):\n",
    "    @functools.wraps(func)\n",
    "    def _generator(random, args):\n",
    "        return np.asarray(func(random, args))\n",
    "\n",
    "    return _generator\n",
    "\n",
    "\n",
    "def single_objective_evaluator(candidates, args):\n",
    "    problem = args[\"problem\"]\n",
    "    return [CombinedObjectives(fit, args) for fit in\n",
    "            problem.evaluator(candidates, args)]\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "        rnd: np.random.RandomState,\n",
    "        func,\n",
    "        **kwargs\n",
    "):\n",
    "    #create dictionaries to store data about initial population, and lines\n",
    "    initial_pop_storage = {}\n",
    "\n",
    "    algorithm = ec.EvolutionaryComputation(rnd)\n",
    "    algorithm.terminator = ec.terminators.generation_termination\n",
    "    algorithm.replacer = ec.replacers.generational_replacement\n",
    "    algorithm.variator = [ec.variators.uniform_crossover, ec.variators.gaussian_mutation]\n",
    "    algorithm.selector = ec.selectors.tournament_selection\n",
    "\n",
    "    algorithm.observer = initial_pop_observer\n",
    "\n",
    "    kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "    kwargs[\"bounder\"] = func.bounder()\n",
    "\n",
    "    final_pop = algorithm.evolve(\n",
    "        evaluator=func,\n",
    "        maximize=False,\n",
    "        generator=None,\n",
    "        initial_pop_storage=initial_pop_storage,\n",
    "        num_var=2,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    #best_guy = final_pop[0].candidate\n",
    "    #best_fitness = final_pop[0].fitness\n",
    "    final_pop_fitnesses = np.asarray([guy.fitness for guy in final_pop])\n",
    "    final_pop_candidates = np.asarray([guy.candidate for guy in final_pop])\n",
    "\n",
    "    sort_indexes = sorted(range(len(final_pop_fitnesses)), key=final_pop_fitnesses.__getitem__)\n",
    "    final_pop_fitnesses = final_pop_fitnesses[sort_indexes]\n",
    "    final_pop_candidates = final_pop_candidates[sort_indexes]\n",
    "\n",
    "    best_guy = final_pop_candidates[0]\n",
    "    best_fitness = final_pop_fitnesses[0]\n",
    "\n",
    "    return best_guy, best_fitness, final_pop\n",
    "\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Samplings methods to implement"
   ],
   "metadata": {
    "id": "3YjLWcgj7OVy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def random_generator(\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        pop: int,\n",
    "        rnd: np.random.Generator,\n",
    ") -> np.ndarray[np.ndarray[float]]:\n",
    "    return np.asarray([rnd.uniform(low=start, high=stop, size=pop) for (start, stop) in boundaries]).T\n",
    "\n",
    "\n",
    "def lhs_generator(\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        pop: int,\n",
    "        rnd: np.random.Generator,\n",
    ") -> np.ndarray[np.ndarray[float]]:\n",
    "    n = len(boundaries)\n",
    "\n",
    "    # generate the intervals\n",
    "    cut = np.linspace(0, 1, pop + 1)\n",
    "\n",
    "    # fill points uniformly in each interval\n",
    "    u = rnd.random([pop, n])\n",
    "    a = cut[:pop]\n",
    "    b = cut[1:pop + 1]\n",
    "    rnd_points = np.zeros_like(u)\n",
    "    for j in range(n):\n",
    "        rnd_points[:, j] = u[:, j] * (b - a) + a\n",
    "\n",
    "    # make the random pairings\n",
    "    h = np.zeros_like(rnd_points)\n",
    "    for j in range(n):\n",
    "        order = rnd.permutation(range(pop))\n",
    "        h[:, j] = rnd_points[order, j]\n",
    "\n",
    "    h = h.T\n",
    "\n",
    "    for (i, (start, stop)) in zip(it.count(0), boundaries):\n",
    "        h[i] = start + (h[i] * (stop - start))\n",
    "\n",
    "    return h.T\n",
    "\n",
    "\n",
    "# ppf_start, ppf_stop = (-2, 2)\n",
    "\n",
    "# if len(boundaries) == 1:\n",
    "#     [(start, stop)] = boundaries\n",
    "#     return start + (abs(ppf_start) + sp.stats.norm.ppf(\n",
    "#         [\n",
    "#             (i + 1 - rnd.uniform()) / pop\n",
    "#             for i\n",
    "#             in rnd.permutation(pop)\n",
    "#         ]\n",
    "#     )) * (stop - start) / (ppf_stop - ppf_start)\n",
    "\n",
    "# return np.asarray(\n",
    "#     [\n",
    "#         start + (abs(ppf_start) + sp.stats.norm.ppf(\n",
    "#             [\n",
    "#                 (i + 1 - rnd.uniform()) / pop\n",
    "#                 for i\n",
    "#                 in rnd.permutation(pop)\n",
    "#             ]\n",
    "#         )) * (stop - start) / (ppf_stop - ppf_start)\n",
    "#         for (start, stop)\n",
    "#         in boundaries\n",
    "#     ]\n",
    "# ).T\n",
    "\n",
    "\n",
    "def halton(\n",
    "        start: int,\n",
    "        stop: int,\n",
    "        base: int\n",
    ") -> Iterator[float]:\n",
    "    n, d = 0, 1\n",
    "    while True:\n",
    "        x = d - n\n",
    "        if x == 1:\n",
    "            n = 1\n",
    "            d *= base\n",
    "        else:\n",
    "            y = d // base\n",
    "            while x <= y:\n",
    "                y //= base\n",
    "            n = (base + 1) * y - x\n",
    "        yield start + ((n / d) * (stop - start))\n",
    "\n",
    "\n",
    "def halton_generator(\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        pop: int,\n",
    "        bases: List[int]\n",
    ") -> np.ndarray[np.ndarray[float]]:\n",
    "    return np.asarray([\n",
    "        np.fromiter(iter=halton(start, stop, base), dtype=float, count=pop) for [(start, stop), base] in\n",
    "        zip(boundaries, bases)\n",
    "    ]).T\n",
    "\n",
    "\n",
    "def ff_generator(\n",
    "        boundaries: List[Tuple[int, int]],\n",
    "        m: int\n",
    ") -> np.ndarray[np.ndarray[float]]:\n",
    "    return np.asarray(\n",
    "        list(it.product(*[\n",
    "            np.linspace(start=start, stop=stop, num=m)\n",
    "            for (start, stop)\n",
    "            in boundaries\n",
    "        ]))\n",
    "    )\n"
   ],
   "metadata": {
    "id": "ic7JlvOI60fo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare() -> None:\n",
    "    m = 50\n",
    "    primes = [2, 3, 5, 7]\n",
    "\n",
    "    for boundaries in [[(0, 10)]]:\n",
    "        pop = m ** len(boundaries)\n",
    "        gs = [\n",
    "            ('uniform', random_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            ('lhs', lhs_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            (f'halton : {primes[:len(boundaries)]}', halton_generator(boundaries, pop, primes[:len(boundaries)])),\n",
    "            ('full factorial', ff_generator(boundaries, m)),\n",
    "        ]\n",
    "\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=2,\n",
    "            ncols=2,\n",
    "            figsize=(2 * 4, 3),\n",
    "            dpi=400,\n",
    "            sharex=True,\n",
    "            sharey=True,\n",
    "        )\n",
    "\n",
    "        axs = it.chain.from_iterable(axs)\n",
    "\n",
    "        for (i, ax, (g, ps)) in zip(it.count(1), axs, gs):\n",
    "            ax.set_anchor('W')\n",
    "            ax.scatter(\n",
    "                ps,\n",
    "                np.full(len(ps), 0),\n",
    "                s=20,\n",
    "                alpha=0.8,\n",
    "                label=g,\n",
    "                c=f'C{i}',\n",
    "            )\n",
    "            ax.set(\n",
    "                aspect='auto',\n",
    "                xlim=boundaries[0],\n",
    "                xticks=[],\n",
    "                yticks=[],\n",
    "                autoscale_on=False,\n",
    "            )\n",
    "            ax.legend(loc='lower left')\n",
    "\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        fig.savefig('comparing/1D.svg')\n",
    "        plt.close('all')\n",
    "\n",
    "    for boundaries in [[(0, 10), (0, 10)]]:\n",
    "        pop = m ** len(boundaries)\n",
    "        gs = [\n",
    "            ('uniform', random_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            ('lhs', lhs_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            (f'halton : {primes[:len(boundaries)]}', halton_generator(boundaries, pop, primes[:len(boundaries)])),\n",
    "            ('full factorial', ff_generator(boundaries, m)),\n",
    "        ]\n",
    "\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=2,\n",
    "            ncols=2,\n",
    "            figsize=(2 * 4, 2 * 4),\n",
    "            dpi=400,\n",
    "            sharex=True,\n",
    "            sharey=True,\n",
    "        )\n",
    "\n",
    "        axs = it.chain.from_iterable(axs)\n",
    "\n",
    "        for (i, ax, (g, ps)) in zip(it.count(1), axs, gs):\n",
    "            ax.set_anchor('W')\n",
    "            ax.scatter(\n",
    "                ps.T[0],\n",
    "                ps.T[1],\n",
    "                s=20,\n",
    "                alpha=0.8,\n",
    "                label=g,\n",
    "                c=f'C{i}',\n",
    "            )\n",
    "            ax.set(\n",
    "                aspect='auto',\n",
    "                xlim=boundaries[0],\n",
    "                ylim=boundaries[1],\n",
    "                xticks=[],\n",
    "                yticks=[],\n",
    "                autoscale_on=False,\n",
    "            )\n",
    "            ax.legend(loc='lower left')\n",
    "\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        fig.savefig('comparing/2D.svg')\n",
    "        plt.close('all')\n",
    "\n",
    "    m = 10\n",
    "    for boundaries in [[(0, 10), (0, 10), (0, 10)]]:\n",
    "        pop = m ** len(boundaries)\n",
    "        gs = [\n",
    "            ('uniform', random_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            ('lhs', lhs_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            (f'halton : {primes[:len(boundaries)]}', halton_generator(boundaries, pop, primes[:len(boundaries)])),\n",
    "            ('full factorial', ff_generator(boundaries, m)),\n",
    "        ]\n",
    "\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=2,\n",
    "            ncols=2,\n",
    "            figsize=(2 * 4, 2 * 4),\n",
    "            dpi=400,\n",
    "            subplot_kw={'projection': '3d'},\n",
    "        )\n",
    "\n",
    "        axs = it.chain.from_iterable(axs)\n",
    "\n",
    "        for (i, ax, (g, ps)) in zip(it.count(1), axs, gs):\n",
    "            ax.set_anchor('W')\n",
    "            ax.scatter(\n",
    "                ps.T[0],\n",
    "                ps.T[1],\n",
    "                ps.T[2],\n",
    "                s=20,\n",
    "                alpha=0.8,\n",
    "                label=g,\n",
    "                c=f'C{i}',\n",
    "            )\n",
    "            ax.set(\n",
    "                aspect='auto',\n",
    "                xlim=boundaries[0],\n",
    "                ylim=boundaries[1],\n",
    "                zlim=boundaries[2],\n",
    "                xticks=[],\n",
    "                yticks=[],\n",
    "                zticks=[],\n",
    "                autoscale_on=False,\n",
    "            )\n",
    "            ax.legend(loc='lower left')\n",
    "\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        fig.savefig('comparing/3D.svg')\n",
    "        plt.close('all')\n",
    "\n",
    "        for (i, (g, ps)) in zip(it.count(1), gs):\n",
    "            fig, axs = plt.subplots(\n",
    "                nrows=2,\n",
    "                ncols=2,\n",
    "                figsize=(2 * 4, 2 * 4),\n",
    "                dpi=400,\n",
    "            )\n",
    "\n",
    "            fig.delaxes(axs[-1][-1])\n",
    "\n",
    "            for (ax, (r, c)) in zip(it.chain.from_iterable(axs), [(0, 1), (2, 1), (0, 2)]):\n",
    "                ax.set_anchor('W')\n",
    "                ax.scatter(\n",
    "                    ps.T[r],\n",
    "                    ps.T[c],\n",
    "                    s=20,\n",
    "                    alpha=0.8,\n",
    "                    c=f'C{i}',\n",
    "                )\n",
    "                ax.set(\n",
    "                    aspect='auto',\n",
    "                    xlim=boundaries[r],\n",
    "                    ylim=boundaries[c],\n",
    "                    xticks=[],\n",
    "                    yticks=[],\n",
    "                    autoscale_on=False,\n",
    "                )\n",
    "\n",
    "            fig.subplots_adjust(wspace=0, hspace=0)\n",
    "            fig.savefig(f'comparing/3D - {g}.svg')\n",
    "            plt.close('all')\n",
    "\n",
    "\n",
    "shutil.rmtree('comparing')\n",
    "Path('comparing').mkdir(parents=True, exist_ok=False)\n",
    "compare()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1: Bayesian Optimization"
   ],
   "metadata": {
    "id": "uNxjVNUu9qBM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def bo() -> None:\n",
    "    shutil.rmtree('bo')\n",
    "    Path('bo').mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "    m = 10\n",
    "    primes = [2, 3, 5, 7]\n",
    "    boundaries = [(0, 1)]\n",
    "    pop = m ** len(boundaries)\n",
    "    gs = [\n",
    "        ('uniform', random_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "        ('lhs', lhs_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "        (f'halton : {primes[:len(boundaries)]}', halton_generator(boundaries, pop, primes[:len(boundaries)])),\n",
    "        ('full factorial', ff_generator(boundaries, m)),\n",
    "    ]\n",
    "\n",
    "    for (g, ps) in gs:\n",
    "        bayesian_optimization(\n",
    "            rnd=np.random.default_rng(seed=0),\n",
    "            generation=10,\n",
    "            model=GaussianProcessRegressor(),\n",
    "            acquisition=probability_of_improvement,\n",
    "            initial_points=ps,\n",
    "            file=f'bo/pi {g}'\n",
    "        )\n",
    "\n",
    "\n",
    "shutil.rmtree('bo')\n",
    "Path('bo').mkdir(parents=True, exist_ok=False)\n",
    "bo()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2: Genetic Algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bfs = [\n",
    "    (\"ackley\", bf.Ackley(), None),\n",
    "    (\"de jong 3\", bf.DeJong3(), None),\n",
    "    (\"keane\", bf.Keane(), -0.675),\n",
    "    (\"picheny goldstein and price\", bf.PichenyGoldsteinAndPrice(), None),\n",
    "    (\"mc cormick\", bf.McCormick(), None),\n",
    "    (\"michalewicz\", bf.Michalewicz(), None),\n",
    "    (\"styblinski and tang\", bf.StyblinskiTang(), None),\n",
    "    (\"easom\", bf.Easom(), None),\n",
    "    (\"pits and holes\", bf.PitsAndHoles(), None),\n",
    "    (\"egg holder\", bf.EggHolder(), None),\n",
    "]\n",
    "\n",
    "\n",
    "def f(fni, history):\n",
    "    x = OptFun(fni)\n",
    "    x.history = history\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ga() -> None:\n",
    "    for (name, fn, minima) in bfs:\n",
    "\n",
    "        m = 10\n",
    "        primes = [2, 3, 5, 7]\n",
    "        boundaries = OptFun(fn).bounds()\n",
    "        pop = m ** len(boundaries)\n",
    "        gs: list[tuple[str, np.ndarray[np.ndarray[float]]]] = [\n",
    "            ('uniform', random_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            ('lhs', lhs_generator(boundaries, pop, np.random.default_rng(seed=0))),\n",
    "            (f'halton : {primes[:len(boundaries)]}', halton_generator(boundaries, pop, primes[:len(boundaries)])),\n",
    "            ('full factorial', ff_generator(boundaries, m)),\n",
    "        ]\n",
    "\n",
    "        for (g, ps) in gs:\n",
    "            ps = ps.tolist()\n",
    "            func = OptFun(fn)\n",
    "\n",
    "            args = dict(\n",
    "                num_vars=2,  # number of dimensions of the search space\n",
    "                gaussian_stdev=1.0,  # standard deviation of the Gaussian mutations\n",
    "                tournament_size=2,\n",
    "                num_elites=1,  # number of elite individuals to maintain in each gen\n",
    "                pop_size=len(ps),  # population size\n",
    "                seeds=ps,\n",
    "                # pop_init_range=func.bounds()[0],  # range for the initial population\n",
    "                max_generations=3 ** 4 - 1,  # number of generations of the GA\n",
    "                crossover_rate=0.9,\n",
    "                mutation_rate=0.1,\n",
    "            )\n",
    "\n",
    "            run_ga(\n",
    "                NumpyRandomWrapper(0),  # seeded random number generator\n",
    "                func,\n",
    "                **args\n",
    "            )\n",
    "\n",
    "            # list(\n",
    "            #     func.history\n",
    "            #     | p.Pipe(lambda xs: more_itertools.windowed(xs, n=args['pop_size'], step=args['pop_size']))\n",
    "            #     | p.map(lambda x: f(fn, x))\n",
    "            #     | p.izip(it.count(0))\n",
    "            #     | p.map(lambda x: x[0].heatmap(file=f'out/heatmap {name} {x[1]}.svg'))\n",
    "            # )\n",
    "\n",
    "            list(\n",
    "                range(1, 5)\n",
    "                | p.map(lambda x: args['pop_size'] * (3 ** x))\n",
    "                | p.map(lambda x: f(fn, func.history[:x]))\n",
    "                | p.izip(it.count(0))\n",
    "                | p.map(lambda x: x[0].heatmapP(\n",
    "                    init=args['pop_size'],\n",
    "                    window=args['pop_size'],\n",
    "                    file=f'ga/heatmap {g} {name} {x[1]}.svg')\n",
    "                        )\n",
    "            )\n",
    "\n",
    "            func.plot(minima=minima, file=f'ga/trend {g} {name}.svg')\n",
    "\n",
    "\n",
    "shutil.rmtree('ga')\n",
    "Path('ga').mkdir(parents=True, exist_ok=False)\n",
    "ga()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this lab, you will need to compare the algorithms studied in the previous lessons with their version enhanced with different DOE techniques.\n",
    "\n",
    "1.   How do the performances increases? Are the algorithms faster to converge, or can they find better solutions? \n",
    "2.   Is there an approach better than the others in terms of performance?\n",
    "3.   How much do the DOEs affect the search cost? \n"
   ],
   "metadata": {
    "id": "gSFPcYQirNga"
   }
  }
 ]
}
