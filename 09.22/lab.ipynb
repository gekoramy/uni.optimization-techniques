{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def folder(f: str):\n",
        "  fp = \"/content/drive/MyDrive/optimization-techniques/\" + f\n",
        "  Path(fp).mkdir(parents = True, exist_ok = True)\n",
        "  return fp"
      ],
      "metadata": {
        "id": "WZDPsBr9k3jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization techniques Lab. 2: Stochastic global optimization\n",
        "## Introduction\n",
        "**Goal.** The goal of this laboratory is to study the application of stochastic global search algorithms on different benchmark functions.\n",
        "\n",
        "We will study two methods: DIRECT and Basin-hopping. Moreover, we will study the effect of their parameters on the outcome of the search. \n",
        "\n",
        "**Getting started.** The following code cell contains the core functions that we will use. Hence, remember to run it every time the Colab runtime is reconnected.\n",
        "\n",
        "You can find a wrapper function for the  two algorithm, together with a wrapper for the benchmark function. \n",
        "\n",
        "The constructor for the *OptFun* class takes in input a benchmark function (we will see later what functions are available). The relevant methods  are 4:\n",
        "1.   *Minima*: return a list of the minimum of the function. The position can be obtained by the parameter *position* and the function value from the *score* parameter.\n",
        "2.   *Bounds*: returns where the function is defined\n",
        "3.   *Heatmap*: show a heatmap of the function highlighting the points visited by the local search\n",
        "4.   *plot*: show the trend of the points visited by the local search. \n",
        "\n",
        "Each instance of *OptFun* stores the history of the point at which the function has been evaluated. The history is never cleaned and can be obtained through *OptFun.history*. Hence, if you reuse the class instance remember to clean the history (*OptFun.history = list()*).\n",
        "\n",
        "---\n",
        "\n",
        "The benchmark functions available comes from the *benchmark_functions* library (imported as *bf*). \n",
        "The complete list of functions available can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FjoLLMc4xqBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install benchmark_functions\n",
        "!pip install scipydirect"
      ],
      "metadata": {
        "id": "-5mxGEjzBTCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZG84ahNwJL5"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import benchmark_functions as bf\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.optimize import basinhopping as spbasinhopping\n",
        "from scipydirect import minimize as spdirect\n",
        "\n",
        "\n",
        "class OptFun():\n",
        "    def __init__(self, wf):\n",
        "        self.f = wf\n",
        "        self.history = []\n",
        "        \n",
        "    def __call__(self, x0):\n",
        "        self.history.append(deepcopy(x0))\n",
        "        return self.f(x0)\n",
        "\n",
        "    def minima(self):\n",
        "        return self.f.minima()\n",
        "        \n",
        "    def bounds(self):\n",
        "        return self._convert_bounds(self.f.suggested_bounds())\n",
        "\n",
        "    def heatmap(self, fn = None):\n",
        "        plt.clf()\n",
        "        resolution = 50\n",
        "        # fig = plt.figure()\n",
        "        # fig.canvas.set_window_title('Benchmark Function: '+self.f._name)\n",
        "        # fig.suptitle(self.f._name)\n",
        "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
        "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
        "        if self.f._n_dimensions>1:\n",
        "            y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
        "            X, Y = np.meshgrid(x, y)\n",
        "            Z = np.asarray([[self.f((X[i][j],Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
        "\n",
        "        plt.contour(x,y,Z,15,linewidths=0.5,colors='k') # hight lines\n",
        "        plt.contourf(x,y,Z,15,cmap='viridis', vmin=Z.min(), vmax=Z.max()) # heat map\n",
        "        plt.xlabel('x')\n",
        "        plt.ylabel('y')\n",
        "        cbar = plt.colorbar()\n",
        "        cbar.set_label('z')\n",
        "        if len(self.history)>0:\t# plot points\n",
        "            xdata = [x[0] for x in self.history]\n",
        "            ydata = [x[1] for x in self.history]\n",
        "            plt.plot(xdata, ydata, \"or-\", markersize=2, linewidth=2)\n",
        "        if fn is None:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.savefig(fn, dpi=400)\n",
        "\n",
        "    def plot(self):\n",
        "        plt.clf()\n",
        "        values = [self.f(v) for v in self.history]\n",
        "        min = func.minima()[0].score\n",
        "        plt.plot(values)\n",
        "        plt.axhline(min, color=\"r\", label=\"optimum\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def _convert_bounds(self, bounds):\n",
        "        new_bounds= []\n",
        "        for i in range(len(bounds[0])):\n",
        "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
        "        return new_bounds\n",
        "    \n",
        "    def current_calls(self):\n",
        "        return len(self.history)\n",
        "\n",
        "\n",
        "def direct(f: OptFun, eps: float = 1e-4, maxiter: int = 1000):\n",
        "    \"\"\"\n",
        "    Optimizes a function by using the DIRECT algorithm.\n",
        "\n",
        "    - f: function to optimize, an instance of OptFun\n",
        "    - eps: regulates the trade-off between local and global exploration.\n",
        "            The smaller the eps, the more local the search process is.\n",
        "            The higher the eps, the more global the search process becomes.\n",
        "    - maxiter: maximum number of iterations\n",
        "    \"\"\"\n",
        "    bounds = f.bounds()\n",
        "    return spdirect(\n",
        "        func,\n",
        "        bounds=bounds,\n",
        "        eps=eps,\n",
        "        maxT=maxiter,\n",
        "        fglobal=-1e100, #Â absolute min\n",
        "        fglper=0.001,   # relative tollerance\n",
        "        volper=-1.0,\n",
        "        sigmaper=-1.0\n",
        "    )\n",
        "\n",
        "\n",
        "def basinhopping(\n",
        "    f: OptFun,\n",
        "    x0: np.ndarray, \n",
        "    T: float = 1.0,\n",
        "    stepsize: float = 0.5, \n",
        "    stepsize_interval: int = 50,\n",
        "    step_update: float = 0.9,\n",
        "    maxiter: int = 1000):\n",
        "    \"\"\"\n",
        "    Optimizes a function by using the Basin-hopping algorithm.\n",
        "\n",
        "    - f: function to optimize, an instance of OptFun\n",
        "    - x0: starting point for the search process\n",
        "    - T: temperature parameter\n",
        "    - stepsize: maximum step size for random displacement\n",
        "    - stepsize_interval: interval for the update of the step size\n",
        "    - step_update: update factor for the step size \n",
        "    - maxiter: maximum number of iterations\n",
        "    \"\"\"\n",
        "    return spbasinhopping(\n",
        "        f,\n",
        "        x0, \n",
        "        niter=maxiter, \n",
        "        T=T, \n",
        "        stepsize=stepsize,\n",
        "        minimizer_kwargs=None,\n",
        "        take_step=None,\n",
        "        accept_test=None,\n",
        "        callback=None,\n",
        "        interval=stepsize_interval,\n",
        "        disp=False,\n",
        "        niter_success=None,\n",
        "        seed=None,\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex 1: DIRECT\n",
        "---\n",
        "In this first exercise we will use DIRECT as a search algorithm\n",
        "## Questions\n",
        "- How does the eps parameter influence the search process?\n",
        "- How does the number of maximum iterations influence the search process?"
      ],
      "metadata": {
        "id": "wlUGOSi4BWGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "func = OptFun(bf.DeJong5())\n",
        "a = direct(func,1e-4, 1000)\n",
        "func.heatmap()\n",
        "func.plot()"
      ],
      "metadata": {
        "id": "sdhCxY63njLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex 2: Basin-hopping\n",
        "---\n",
        "In this first exercise we will use Basin-hopping as a search algorithm\n",
        "## Questions\n",
        "- What is the influence of the following parameters on the search process?\n",
        "    - T\n",
        "    - stepsize \n",
        "    - stepsize_interval\n",
        "    - step_update\n",
        "- How does the number of maximum iterations influence the search process?\n",
        "- How does the starting point influence the search process?"
      ],
      "metadata": {
        "id": "NMPANeRJBkVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "func = OptFun(bf.DeJong5())\n",
        "a = basinhopping(func, [30,30])\n",
        "func.heatmap()\n",
        "func.plot()"
      ],
      "metadata": {
        "id": "CjVHVO5F3_im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General questions\n",
        "- How do the approaches seen in today's lab compare to the one seen in the previous lab?"
      ],
      "metadata": {
        "id": "LCAigJgN62SF"
      }
    }
  ]
}