{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 7: Bio-Inspired optimization\n",
    "In this lab, we will study the parameters involved in bio-inspired optimization approaches.\n",
    "\n",
    "In the following (hidden) block, the utilities used for running the experiments are implemented.\n",
    "\n",
    "The list of available benchmark functions can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions)\n",
    "\n",
    "**NOTE**: When studying the effect of the parameters is *extremely* important to vary just one parameter at a time. Therefore, you are suggested to study one parameter by fixing all the others, and then moving to the next.\n",
    "\n",
    "Moreover, when comparing different algorithms, is *very* important to run each of them several times (e.g., 30) by using different initial random seeds.\n"
   ],
   "metadata": {
    "id": "1LFQ4RnHpEMu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install cma\n",
    "!pip install inspyred\n",
    "!pip install benchmark_functions"
   ],
   "metadata": {
    "id": "HbFs_V7eGmL3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666800388583,
     "user_tz": -120,
     "elapsed": 14661,
     "user": {
      "displayName": "Andrea Ferigo",
      "userId": "17153632128544353424"
     }
    },
    "outputId": "8a206537-9f2d-49f8-e8a2-b8ba58a4d893"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0qLDcl3jj0f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666800389973,
     "user_tz": -120,
     "elapsed": 1394,
     "user": {
      "displayName": "Andrea Ferigo",
      "userId": "17153632128544353424"
     }
    }
   },
   "outputs": [],
   "source": [
    "import cma\n",
    "import inspyred\n",
    "import importlib\n",
    "import functools\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from inspyred import ec\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "import benchmark_functions as bf\n",
    "from matplotlib import pyplot as plt\n",
    "from inspyred.ec import EvolutionaryComputation\n",
    "from inspyred.ec import selectors, replacers, terminators\n",
    "\n",
    "GLOBAL = 'Global'\n",
    "INDIVIDUAL = 'Individual'\n",
    "CORRELATED = 'Correlated'\n",
    "STAR = 'star'\n",
    "RING = 'ring'\n",
    "\n",
    "\n",
    "class OptFun():\n",
    "    def __init__(self, wf):\n",
    "        self.f = wf\n",
    "        self.history = []\n",
    "        self.__name__ = f'OptFun({wf.__class__})'\n",
    "\n",
    "    def __call__(self, candidates, *args, **kwargs):\n",
    "        y = []\n",
    "        for x0 in candidates:\n",
    "            self.history.append(deepcopy(x0))\n",
    "            y.append(self.f(x0))\n",
    "        return y\n",
    "\n",
    "    def minima(self):\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounder(self):\n",
    "        def fcn(candidate, *args):\n",
    "            bounds = self.f.suggested_bounds()\n",
    "\n",
    "            for i, (m, M) in enumerate(zip(*bounds)):\n",
    "                if candidate[i] < m:\n",
    "                    candidate[i] = m\n",
    "                if candidate[i] > M:\n",
    "                    candidate[i] = M\n",
    "            return candidate\n",
    "\n",
    "        return fcn\n",
    "\n",
    "    def bounds(self):\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def heatmap(self, fn=None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        # fig.canvas.set_window_title('Benchmark Function: ' + self.f._name)\n",
    "        fig.suptitle(self.f._name)\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        if self.f._n_dimensions > 1:\n",
    "            y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Z = np.asarray([[self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x, y, Z, 15, linewidths=0.5, colors='k')  # hight lines\n",
    "        plt.contourf(x, y, Z, 15, cmap='viridis', vmin=Z.min(), vmax=Z.max())  # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history) > 0:  # plot points\n",
    "            xdata = [x[0] for x in self.history]\n",
    "            ydata = [x[1] for x in self.history]\n",
    "            plt.plot(xdata, ydata, \"or-\", markersize=2, linewidth=2)\n",
    "        if fn is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(fn, dpi=400)\n",
    "\n",
    "    def plot(self):\n",
    "        plt.clf()\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        min = func.minima()[0].score\n",
    "        plt.plot(values)\n",
    "        plt.axhline(min, color=\"r\", label=\"optimum\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_bounds(self, bounds):\n",
    "        new_bounds = []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self):\n",
    "        return len(self.history)\n",
    "\n",
    "\n",
    "def choice_without_replacement(rng, n, size):\n",
    "    result = set()\n",
    "    while len(result) < size:\n",
    "        result.add(rng.randint(0, n))\n",
    "    return result\n",
    "\n",
    "\n",
    "class NumpyRandomWrapper(RandomState):\n",
    "    def __init__(self, seed=None):\n",
    "        super(NumpyRandomWrapper, self).__init__(seed)\n",
    "\n",
    "    def sample(self, population, k):\n",
    "        if isinstance(population, int):\n",
    "            population = range(population)\n",
    "\n",
    "        return asarray([population[i] for i in\n",
    "                        choice_without_replacement(self, len(population), k)])\n",
    "        #return #self.choice(population, k, replace=False)\n",
    "\n",
    "    def random(self):\n",
    "        return self.random_sample()\n",
    "\n",
    "    def gauss(self, mu, sigma):\n",
    "        return self.normal(mu, sigma)\n",
    "\n",
    "\n",
    "def initial_pop_observer(population, num_generations, num_evaluations, args):\n",
    "    if num_generations == 0:\n",
    "        args[\"initial_pop_storage\"][\"individuals\"] = asarray([guy.candidate\n",
    "                                                              for guy in population])\n",
    "        args[\"initial_pop_storage\"][\"fitnesses\"] = asarray([guy.fitness\n",
    "                                                            for guy in population])\n",
    "\n",
    "\n",
    "def generator(random, args):\n",
    "    return asarray([random.uniform(args[\"pop_init_range\"][0],\n",
    "                                   args[\"pop_init_range\"][1])\n",
    "                    for _ in range(args[\"num_vars\"])])\n",
    "\n",
    "\n",
    "def generator_wrapper(func):\n",
    "    @functools.wraps(func)\n",
    "    def _generator(random, args):\n",
    "        return asarray(func(random, args))\n",
    "\n",
    "    return _generator\n",
    "\n",
    "\n",
    "def single_objective_evaluator(candidates, args):\n",
    "    problem = args[\"problem\"]\n",
    "    return [CombinedObjectives(fit, args) for fit in\n",
    "            problem.evaluator(candidates, args)]\n",
    "\n",
    "\n",
    "def run_ga(random, func, num_vars=0, maximize=False, **kwargs):\n",
    "    #create dictionaries to store data about initial population, and lines\n",
    "    initial_pop_storage = {}\n",
    "\n",
    "    algorithm = ec.EvolutionaryComputation(random)\n",
    "    algorithm.terminator = ec.terminators.generation_termination\n",
    "    algorithm.replacer = ec.replacers.generational_replacement\n",
    "    algorithm.variator = [ec.variators.uniform_crossover, ec.variators.gaussian_mutation]\n",
    "    algorithm.selector = ec.selectors.tournament_selection\n",
    "\n",
    "    algorithm.observer = initial_pop_observer\n",
    "\n",
    "    kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "\n",
    "    kwargs[\"bounder\"] = func.bounder()\n",
    "    kwargs[\"generator\"] = generator\n",
    "\n",
    "    final_pop = algorithm.evolve(evaluator=func,\n",
    "                                 maximize=False,\n",
    "                                 initial_pop_storage=initial_pop_storage,\n",
    "                                 num_vars=num_vars,\n",
    "                                 **kwargs)\n",
    "\n",
    "    #best_guy = final_pop[0].candidate\n",
    "    #best_fitness = final_pop[0].fitness\n",
    "    final_pop_fitnesses = asarray([guy.fitness for guy in final_pop])\n",
    "    final_pop_candidates = asarray([guy.candidate for guy in final_pop])\n",
    "\n",
    "    sort_indexes = sorted(range(len(final_pop_fitnesses)), key=final_pop_fitnesses.__getitem__)\n",
    "    final_pop_fitnesses = final_pop_fitnesses[sort_indexes]\n",
    "    final_pop_candidates = final_pop_candidates[sort_indexes]\n",
    "\n",
    "    best_guy = final_pop_candidates[0]\n",
    "    best_fitness = final_pop_fitnesses[0]\n",
    "\n",
    "    return best_guy, best_fitness, final_pop\n",
    "\n",
    "\n",
    "class ES(EvolutionaryComputation):\n",
    "    \"\"\"Evolution Strategy EC\n",
    "    \n",
    "    This class is a stub for you to implement progressively more \n",
    "    sophisticated evolution strategies.  \n",
    "    \n",
    "    Optional keyword arguments in ``evolve`` args parameter that you \n",
    "    will need add support for:\n",
    "    \n",
    "    - *strategy_mode* -- One of {None, 'global', 'individual', 'correlated'}\n",
    "    - *epsilon* -- the minimum allowed strategy parameter (default 0.00001)\n",
    "    - *tau* -- a global proportionality constant (default None)\n",
    "    - *tau_i* -- an individual proportionality constant (default None)\n",
    "    - *num_offspring* -- number of offspring to generate at each iteration\n",
    "                        (``\\\\lambda``) should be a multiple of \\\\mu\n",
    "    - *mixing_number* -- mixing number (``\\\\rho``) (number of parents \n",
    "                        involved in producing each offspring), \n",
    "                        default 1 (no-mixing)\n",
    "    \n",
    "    If *tau* is ``None``, it will be set to ``1 / sqrt(2*n)``, where\n",
    "    ``n`` is the length of a candidate. If *tau_i* is ``None``, it will be\n",
    "    set to ``1 / sqrt(2*sqrt(n))``.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, random):\n",
    "        EvolutionaryComputation.__init__(self, random)\n",
    "        self.selector = selectors.default_selection\n",
    "        self.variator = self._internal_variation\n",
    "        #self.replacer = replacers.comma_replacement\n",
    "        self.replacer = replacers.plus_replacement\n",
    "\n",
    "    def elementary_rotation(self, p, q, alphas):\n",
    "        R = ones((self.num_vars, self.num_vars))\n",
    "\n",
    "        # taken from Schwefel et al \"Contemporary Evolution Strategies\"\n",
    "        k = int(0.5 * (2 * self.num_vars - p - 1) * (p + 2) -\n",
    "                2 * self.num_vars + q)\n",
    "        cos_alpha = cos(alphas[k])\n",
    "        sin_alpha = sin(alphas[k])\n",
    "        R[p][p] = cos_alpha\n",
    "        R[q][q] = cos_alpha\n",
    "        R[p][q] = -sin_alpha\n",
    "        R[q][p] = sin_alpha\n",
    "        return R\n",
    "\n",
    "    def _internal_variation(self, random, candidates, args):\n",
    "        tau = args.setdefault('tau', None)\n",
    "        tau_i = args.setdefault('tau', None)\n",
    "        epsilon = args.setdefault('epsilon', 0.00001)\n",
    "\n",
    "        # num_offspring (\\\\lambda)\n",
    "        num_offspring = args.setdefault('num_offspring', len(candidates))\n",
    "\n",
    "        mixing_number = args.setdefault('mixing_number', 1)\n",
    "\n",
    "        if num_offspring % len(candidates) != 0:\n",
    "            raise Exception(\"num_offspring (\\\\lambda) should be a multiple \" +\n",
    "                            \"of pop_size (\\\\mu)\")\n",
    "\n",
    "        mutants = []\n",
    "\n",
    "        if tau is None:\n",
    "            tau = 1. / sqrt(2 * self.num_vars)\n",
    "        if tau_i is None:\n",
    "            tau_i = 1. / sqrt(2 * sqrt(self.num_vars))\n",
    "\n",
    "        while len(mutants) < num_offspring:\n",
    "            parent_family_indices = random.sample([*range(len(candidates))],\n",
    "                                                  mixing_number)\n",
    "            parent_family = asarray([candidates[i] for i in\n",
    "                                     parent_family_indices])\n",
    "            parent = parent_family.mean(0)\n",
    "\n",
    "            cand = parent[:self.num_vars].copy()\n",
    "            if self.strategy_mode is None:\n",
    "                strat = []\n",
    "                sigma = args.setdefault('sigma', 1.0)\n",
    "                if isinstance(random, NumpyRandomWrapper):\n",
    "                    cand += random.normal(0, sigma, cand.shape)\n",
    "                else:\n",
    "                    for i, c in enumerate(cand):\n",
    "                        cand[i] = c + random.gauss(0, sigma)\n",
    "\n",
    "            else:\n",
    "                strat = parent[self.num_vars:].copy()\n",
    "\n",
    "                if self.strategy_mode is GLOBAL:\n",
    "                    sigmas = strat\n",
    "                else:\n",
    "                    sigmas = strat[:self.num_vars]  #view into strat\n",
    "\n",
    "                e_global = tau * random.gauss(0, 1)\n",
    "\n",
    "                # more efficient with sumpy\n",
    "                if isinstance(random, NumpyRandomWrapper):\n",
    "                    sigmas *= exp(e_global + tau_i\n",
    "                                  * random.normal(0, 1, sigmas.shape))\n",
    "                    sigmas = maximum(sigmas, epsilon)\n",
    "                else:\n",
    "                    for i, s in enumerate(sigmas):\n",
    "                        sigmas[i] = s * exp(e_global +\n",
    "                                            tau_i * random.gauss(0, 1))\n",
    "                        sigmas[i] = max(strat[i], epsilon)\n",
    "\n",
    "                if self.strategy_mode is CORRELATED:\n",
    "                    alphas = strat[self.num_vars:]  #another view into strat\n",
    "                    beta_squared = (5. * pi / 180) ** 2  # 5 deg squared\n",
    "                    if isinstance(random, NumpyRandomWrapper):\n",
    "                        alphas += (random.normal(0, beta_squared,\n",
    "                                                 alphas.shape)\n",
    "                                   + pi)\n",
    "                        alphas %= (2 * pi)\n",
    "                        alphas -= pi\n",
    "                    else:\n",
    "                        for j, a in enumerate(alphas):\n",
    "                            alphas[j] = ((a + random.gauss(0, beta_squared)\n",
    "                                          + pi) % (2 * pi)) - pi\n",
    "\n",
    "                if self.strategy_mode is GLOBAL:\n",
    "                    sigma = sigmas[0]\n",
    "                    if isinstance(random, NumpyRandomWrapper):\n",
    "                        cand = cand + random.normal(0, sigma, cand.shape)\n",
    "                    else:\n",
    "                        for i, c in enumerate(cand):\n",
    "                            cand[i] = c + random.gauss(0, sigma)\n",
    "                elif self.strategy_mode is INDIVIDUAL:\n",
    "                    if isinstance(random, NumpyRandomWrapper):\n",
    "                        cand += random.multivariate_normal(\n",
    "                            zeros(self.num_vars),\n",
    "                            diag(sigmas ** 2))\n",
    "                    else:\n",
    "                        for i, (c, s) in enumerate(zip(cand, sigmas)):\n",
    "                            cand[i] = c + random.gauss(0, s)\n",
    "                else:\n",
    "                    # build correlation matrix\n",
    "                    T = reduce(dot,\n",
    "                               [reduce(dot,\n",
    "                                       [self.elementary_rotation(p, q, alphas)\n",
    "                                        for q in range(p + 1, self.num_vars)])\n",
    "                                for p in range(self.num_vars - 1)])\n",
    "                    if isinstance(random, NumpyRandomWrapper):\n",
    "                        cand += random.multivariate_normal(\n",
    "                            zeros(self.num_vars),\n",
    "                            dot(T, diag(sigmas ** 2)))\n",
    "                    else:\n",
    "                        raise Exception(\"NumpyRandomWrapper required\" +\n",
    "                                        \" for correlated mutations\")\n",
    "\n",
    "            cand = self.bounder(cand, args)\n",
    "            cand = np.concatenate((cand, strat))\n",
    "            mutants.append(cand)\n",
    "\n",
    "        return mutants\n",
    "\n",
    "    def _internal_evaluator(self, func):\n",
    "        @functools.wraps(func)\n",
    "        def evaluator(candidates, args):\n",
    "            # convert candidates to array and then back to list\n",
    "            # makes slicing easier\n",
    "            return func(list(asarray(candidates)[:, 0:self.num_vars]), args)\n",
    "\n",
    "        return evaluator\n",
    "\n",
    "    def strategize(self, generator):\n",
    "        \"\"\"Add strategy parameters to candidates created by a generator.\n",
    "        \n",
    "        This function decorator is used to provide a means of adding strategy \n",
    "        parameters to candidates created by a generator. The generator function \n",
    "        is modifed to extend the candidate with strategy parameters based on\n",
    "        the strategy_mode argument passed to evolve. \n",
    "        \n",
    "        Each strategy parameter is initialized to a random value:\n",
    "        in [0, 1] for ``\\\\sigma_i`` and in [-pi,pi] for ``\\\\alpha_i``\n",
    "                \n",
    "        \"\"\"\n",
    "\n",
    "        @functools.wraps(generator)\n",
    "        def strategy_generator(random, args):\n",
    "            candidate = generator(random, args)\n",
    "            if self.strategy_mode is None:\n",
    "                return candidate\n",
    "            elif self.strategy_mode is GLOBAL:\n",
    "                return np.concatenate((candidate, [random.random()]))\n",
    "            else:\n",
    "                sigmas = [random.random() for _ in range(self.num_vars)]\n",
    "                if self.strategy_mode is INDIVIDUAL:\n",
    "                    return np.concatenate((candidate, sigmas))\n",
    "                elif self.strategy_mode is CORRELATED:\n",
    "                    # since have python random, do it like this... would be \n",
    "                    # better with numpy\n",
    "                    alphas = [random.uniform(-pi, pi)\n",
    "                              for _ in range((self.num_vars ** 2 -\n",
    "                                              self.num_vars) // 2)]\n",
    "                    return np.concatenate((candidate, alphas, sigmas))\n",
    "\n",
    "        return strategy_generator\n",
    "\n",
    "    def evolve(self, generator, evaluator, pop_size=100, seeds=None,\n",
    "               maximize=False, bounder=None, strategy_mode=None, num_vars=None,\n",
    "               **args):\n",
    "        self.strategy_mode = strategy_mode\n",
    "        self.num_vars = num_vars\n",
    "\n",
    "        generator = self.strategize(generator)\n",
    "        evaluator = self._internal_evaluator(evaluator)\n",
    "        return EvolutionaryComputation.evolve(self, generator, evaluator,\n",
    "                                              pop_size, maximize=maximize,\n",
    "                                              num_vars=num_vars,\n",
    "                                              bounder=bounder, **args)\n",
    "\n",
    "\n",
    "def run_es(random, func, num_vars=0, maximize=False, **kwargs):\n",
    "    #create dictionaries to store data about initial population, and lines\n",
    "    initial_pop_storage = {}\n",
    "\n",
    "    algorithm = ES(random)\n",
    "    algorithm.terminator = terminators.generation_termination\n",
    "\n",
    "    algorithm.observer = initial_pop_observer\n",
    "\n",
    "    kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "    kwargs[\"bounder\"] = func.bounder()\n",
    "    kwargs[\"generator\"] = generator_wrapper(generator)\n",
    "\n",
    "    final_pop = algorithm.evolve(evaluator=func,\n",
    "                                 maximize=maximize,\n",
    "                                 initial_pop_storage=initial_pop_storage,\n",
    "                                 num_vars=num_vars,\n",
    "                                 **kwargs)\n",
    "\n",
    "    #best_guy = final_pop[0].candidate[0:num_vars]\n",
    "    #best_fitness = final_pop[0].fitness\n",
    "    final_pop_fitnesses = asarray([guy.fitness for guy in final_pop])\n",
    "    final_pop_candidates = asarray([guy.candidate[0:num_vars] for guy in final_pop])\n",
    "\n",
    "    sort_indexes = sorted(range(len(final_pop_fitnesses)), key=final_pop_fitnesses.__getitem__)\n",
    "    final_pop_fitnesses = final_pop_fitnesses[sort_indexes]\n",
    "    final_pop_candidates = final_pop_candidates[sort_indexes]\n",
    "\n",
    "    best_guy = final_pop_candidates[0]\n",
    "    best_fitness = final_pop_fitnesses[0]\n",
    "\n",
    "    return best_guy, best_fitness, final_pop\n",
    "\n",
    "\n",
    "def run_cmaes(random, func, **kwargs):\n",
    "    es = cma.CMAEvolutionStrategy(generator(random, kwargs),\n",
    "                                  kwargs[\"sigma\"],\n",
    "                                  {'popsize': kwargs[\"num_offspring\"],\n",
    "                                   'seed': random.randint(0, 1000),\n",
    "                                   'CMA_mu': kwargs[\"pop_size\"]})\n",
    "    gen = 0\n",
    "    while gen <= kwargs[\"max_generations\"]:\n",
    "        candidates = es.ask()  # get list of new solutions\n",
    "        candidates = list(map(func.bounder(), candidates))\n",
    "        fitnesses = func(candidates, kwargs)\n",
    "\n",
    "        es.tell(candidates, fitnesses)\n",
    "        gen += 1\n",
    "\n",
    "    final_pop = asarray(es.ask())\n",
    "    final_pop_fitnesses = asarray(func(final_pop, kwargs))\n",
    "\n",
    "    best_guy = es.best.x\n",
    "    best_fitness = es.best.f\n",
    "\n",
    "    return best_guy, best_fitness\n",
    "\n",
    "\n",
    "def run_pso(random, func, num_vars=0, maximize=False, **kwargs):\n",
    "    #create dictionaries to store data about initial population, and lines\n",
    "    initial_pop_storage = {}\n",
    "\n",
    "    algorithm = inspyred.swarm.PSO(random)\n",
    "    algorithm.topology = inspyred.swarm.topologies.star_topology\n",
    "    algorithm.terminator = ec.terminators.generation_termination\n",
    "\n",
    "    algorithm.observer = initial_pop_observer\n",
    "\n",
    "    if \"topology\" in kwargs:\n",
    "        if kwargs[\"topology\"] is STAR:\n",
    "            algorithm.topology = inspyred.swarm.topologies.star_topology\n",
    "        elif kwargs[\"topology\"] is RING:\n",
    "            algorithm.topology = inspyred.swarm.topologies.ring_topology\n",
    "\n",
    "    kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "    kwargs[\"bounder\"] = func.bounder()\n",
    "    kwargs[\"generator\"] = generator\n",
    "\n",
    "    final_pop = algorithm.evolve(evaluator=func,\n",
    "                                 maximize=maximize,\n",
    "                                 initial_pop_storage=initial_pop_storage,\n",
    "                                 num_vars=num_vars,\n",
    "                                 **kwargs)\n",
    "\n",
    "    final_pop_fitnesses = asarray([guy.fitness for guy in final_pop])\n",
    "    final_pop_candidates = asarray([guy.candidate for guy in final_pop])\n",
    "\n",
    "    sort_indexes = sorted(range(len(final_pop_fitnesses)), key=final_pop_fitnesses.__getitem__)\n",
    "    final_pop_fitnesses = final_pop_fitnesses[sort_indexes]\n",
    "    final_pop_candidates = final_pop_candidates[sort_indexes]\n",
    "\n",
    "    best_guy = final_pop_candidates[0]\n",
    "    best_fitness = final_pop_fitnesses[0]\n",
    "\n",
    "    return best_guy, best_fitness, final_pop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1: Genetic Algorithms\n",
    "1. Compare the results of mutation-only vs crossover-only\n",
    "2. Fixing the mutation probability, compare different values for the crossover\n",
    "3. How does the selective pressure (i.e., tournament size) affect the search?\n",
    "4. Compare the search process on different benchmark functions"
   ],
   "metadata": {
    "id": "TE2uwsRa5sTS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from random import Random\n",
    "\n",
    "func = OptFun(bf.Ackley(2))\n",
    "\n",
    "args = {}\n",
    "args[\"num_vars\"] = 2  # Number of dimensions of the search space\n",
    "args[\"gaussian_stdev\"] = 1.0  # Standard deviation of the Gaussian mutations\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 20  # population size\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"max_generations\"] = 50  # Number of generations of the GA\n",
    "args[\"crossover_rate\"] = 0.0\n",
    "args[\"mutation_rate\"] = 1.0\n",
    "\n",
    "run_ga(\n",
    "    Random(0),  # Seeded random number generator\n",
    "    func,\n",
    "    **args\n",
    ")\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ],
   "metadata": {
    "id": "iX0W_9p1r7Fr",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "outputId": "51723ee7-d02e-470c-f6d4-453eab94146e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666800406287,
     "user_tz": -120,
     "elapsed": 1907,
     "user": {
      "displayName": "Andrea Ferigo",
      "userId": "17153632128544353424"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2: Evolution Strategies\n",
    "1. How does the number of offspring  $\\lambda$ parameter affect the search?\n",
    "2. How does the mixing number $\\rho$ affect the search?\n",
    "3. Describe the impact of the different strategies (None/GLOBAL/INDIVIDUAL) on the search process."
   ],
   "metadata": {
    "id": "U6KsHdbEH3l1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "func = OptFun(bf.Ackley(2))\n",
    "\n",
    "args = {}\n",
    "args[\"num_vars\"] = 2  # Number of dimensions of the search space\n",
    "args[\"max_generations\"] = 50\n",
    "args[\"sigma\"] = 1.0  # default standard deviation\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"pop_size\"] = 20  # mu\n",
    "args[\"num_offspring\"] = 100  #lambda\n",
    "args[\"mixing_number\"] = 5  #rho\n",
    "args[\"strategy_mode\"] = None\n",
    "\n",
    "run_es(\n",
    "    Random(0),  # Seeded random number generator\n",
    "    func,\n",
    "    **args\n",
    ")\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ],
   "metadata": {
    "id": "JyeK3niU8B2B",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "outputId": "3c87987e-fe10-40fc-e137-15d85a007d9b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3: CMA-ES\n",
    "1. Can CMA-ES find the solution quicker (i.e.,  with less evaluations) than ES?\n",
    "2. What is the impact of $\\mu$, $\\lambda$ and $\\sigma$ on the search process?"
   ],
   "metadata": {
    "id": "xTagjCIpOOdh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "func = OptFun(bf.Ackley(2))\n",
    "\n",
    "args = {}\n",
    "args[\"num_vars\"] = 2  # Number of dimensions of the search space\n",
    "args[\"max_generations\"] = 50\n",
    "args[\"sigma\"] = 1.0  # default standard deviation\n",
    "args[\"pop_size\"] = 20  #mu\n",
    "args[\"num_offspring\"] = 100  #lambda\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "\n",
    "run_cmaes(\n",
    "    Random(0),  # Seeded random number generator\n",
    "    func,\n",
    "    **args\n",
    ")\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "crHzqqQsFpxe",
    "outputId": "02d5ede4-a3e8-407c-a429-4cb1f946a1bf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1666800439137,
     "user_tz": -120,
     "elapsed": 2402,
     "user": {
      "displayName": "Andrea Ferigo",
      "userId": "17153632128544353424"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [Optional] Exercise 4: PSO\n",
    "1. How does PSO compare to GA on different benchmark functions?\n",
    "2. How does PSO compare to ES on different benchmark functions?\n",
    "3. Vary the pop_size and the n. of generations in such a way that their product is always constant, and compare the outcome of the search (over multiple runs). What is better? To have higher pop_size or higher n. of generations?\n"
   ],
   "metadata": {
    "id": "2AiwWjlVTMAC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "func = OptFun(bf.Ackley(2))\n",
    "\n",
    "args = {}\n",
    "args[\"num_vars\"] = 2  # Number of dimensions of the search space\n",
    "args[\"topology\"] = RING  #RING, STAR\n",
    "args[\"neighborhood_size\"] = 5  #used only for the ring topology\n",
    "args[\"inertia\"] = 0.5\n",
    "args[\"cognitive_rate\"] = 2.1\n",
    "args[\"pop_size\"] = 20  #mu\n",
    "args[\"social_rate\"] = 2.1\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"max_generations\"] = 50\n",
    "\n",
    "run_pso(\n",
    "    Random(0),  # Seeded random number generator\n",
    "    func,\n",
    "    **args\n",
    ")\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "l_KDdpoXL0_-",
    "outputId": "6170cda0-552c-43c3-dc59-e6cdfb16923a"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
